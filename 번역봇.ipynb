{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    " \n",
    "def generate_response(system_message, user_message, model=\"gemma2:9b\", temperature=0, top_p=1, top_k=1):\n",
    "    client = ollama.Client()\n",
    "    response = client.chat(\n",
    "        model=model,\n",
    "        stream=True,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": user_message}\n",
    "        ],\n",
    "        options={\n",
    "            \"temperature\": temperature,\n",
    "            \"top_p\": top_p,\n",
    "            \"top_k\": top_k,\n",
    "        }\n",
    "    )\n",
    "    full_response = \"\"    \n",
    "    for chunk in response:\n",
    "        content = chunk['message']['content']\n",
    "        print(content, end='', flush=True)  # 실시간 스트리밍 출력\n",
    "        full_response += content  # 전체 응답 구성      \n",
    "    return full_response\n",
    " \n",
    "# 예시 사용법\n",
    "system_msg = \"\"\"\n",
    "### Instruction\n",
    "너는 이름이 폴리텍봇이야.\n",
    "너는 지금부터 전문 번역가야  \n",
    "너의 역할은 주어진 언어를 영어로 번역하는 것이야.\n",
    "너는 사용자의 입력을 출력하고, 그 아래에 번역한 내용을 넣어줘.\n",
    " \n",
    "원문 : 사용자 입력\n",
    "번역 : 사용자 입력을 번역한 내용\n",
    " \n",
    "출력 템플릿은 다음과 같아. 반드시 번역 결과만 출력해야해.\n",
    "<번역> My name is Hong-gil-dong.\n",
    "\"\"\"\n",
    " \n",
    "text = \"나는 밥을 학생식당에서 먹어서 배가 너무 불러.\"\n",
    "user_msg = f\"\"\"\n",
    "### Question\n",
    " <원문> {text}\n",
    " <번역>\n",
    "\"\"\"\n",
    " \n",
    "response = generate_response(system_msg, user_msg, model=\"gemma2:9b\", temperature=0.5, top_p=1, top_k=1)\n",
    "# print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
