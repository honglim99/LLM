{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5696, -0.3220, -0.5389,  ...,  0.8540,  0.6738, -0.0364],\n",
      "        [-0.2032, -0.2217,  0.0109,  ..., -0.3850, -0.1776, -0.1213],\n",
      "        [-0.1083,  0.4838, -0.4401,  ...,  0.6547,  0.0280, -0.5172],\n",
      "        [-0.2239, -0.1685,  0.6479,  ..., -0.0646,  0.1184, -0.6720],\n",
      "        [-0.1381, -0.3505, -0.6734,  ...,  0.2757,  0.4943,  0.0418]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    " \n",
    "embedder = SentenceTransformer(\"jhgan/ko-sroberta-multitask\")\n",
    "\n",
    "# Corpus with example sentences\n",
    "corpus = [\"한국폴리텍대학은 산업 현장에서 필요한 기술과 기능 인력을 양성하는 것을 목표로 합니다.\",\n",
    "            \"봄이 되면 공원에는 다양한 꽃들이 피어나 아름다운 풍경을 연출합니다.\",\n",
    "            \"인공지능 기술은 의료, 금융, 제조 등 다양한 산업 분야에서 혁신을 가져오고 있습니다.\",\n",
    "            \"오늘 날씨가 매우 맑아서 산책하기에 좋은 날입니다.\",\n",
    "            \"한국의 전통 음식인 김치는 발효 과정을 통해 풍부한 맛과 향을 지니게 됩니다.\"]\n",
    " \n",
    "corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)\n",
    "print(corpus_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: 기술을 배워보고 싶어.\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "한국폴리텍대학은 산업 현장에서 필요한 기술과 기능 인력을 양성하는 것을 목표로 합니다. (Score: 0.4760)\n",
      "인공지능 기술은 의료, 금융, 제조 등 다양한 산업 분야에서 혁신을 가져오고 있습니다. (Score: 0.2762)\n",
      "오늘 날씨가 매우 맑아서 산책하기에 좋은 날입니다. (Score: 0.1113)\n",
      "한국의 전통 음식인 김치는 발효 과정을 통해 풍부한 맛과 향을 지니게 됩니다. (Score: 0.1032)\n",
      "봄이 되면 공원에는 다양한 꽃들이 피어나 아름다운 풍경을 연출합니다. (Score: 0.0720)\n"
     ]
    }
   ],
   "source": [
    "# Query sentences:\n",
    "queries = ['기술을 배워보고 싶어.']\n",
    " \n",
    "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "top_k = 5\n",
    "for query in queries:\n",
    " query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    " cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
    " cos_scores = cos_scores.cpu()\n",
    " \n",
    " #We use np.argpartition, to only partially sort the top_k results\n",
    " top_results = np.argpartition(-cos_scores, range(top_k))[0:top_k]\n",
    " \n",
    " \n",
    " \n",
    " print(\"\\n\\n======================\\n\\n\")\n",
    " print(\"Query:\", query)\n",
    " print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    " \n",
    " for idx in top_results[0:top_k]:\n",
    "  print(corpus[idx].strip(), \"(Score: %.4f)\" % (cos_scores[idx]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
