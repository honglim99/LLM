학습데이터준비 -> 어떤 인공지능에 어떤 데이터들을 학습시키는가

인공지능 학습은 노가다!!

과제
보고서 자동생성 -> 난이도 매우 높음

- 폴리텍 대학 학칙 챗봇
- 미세먼지 안내 챗봇

트랜스포머(Transformer) : 획기적인 자연어 처리 알고리즘
- 중대한 패러다임 전환을 일으킨 알고리즘
- 이전 언어모델들은 속도가 느리고, 입력 문장길이가 길어지면 성능하락
- LLM이 문장에서 중요한 부분에 집중할 수 있도록 하고 단어들의 상관관계를 파악하게함
- LLM이 자연어를 이해하고 인간과 유사한 결과를 생성할 수 있게 함

트랜스포머의 주요 개념
- 셀프 어텐션 : 텍스트에서 각 단어가 문장 내의 다른 단어들과 얼마나 관련이 있는지를 파악하는 메커니즘
- 멀티-헤드 어텐션 : 셀프-어텐션을 여러 '헤드'로 나누어 동시에 수행, 문장의 서로 다른 부분에 집중하여, 다양한 관점에서 문맥을 이해
- 포지셔널 인코딩 : 트랜스포머 모델에 단어의 순서 정보를 제공하여 각 단어의 위치에 따라 고유한 값을 부여하여, 모델이 단어의 순서를 인식

!!! gpt가 어떻게 구성되는지 알아두는게 면접에서 좋다.

gpt는 확률 생성모델 - 뒤에올 말을 확률을 계산하여 생성한다.
-> 그래서 hallucination 발생

BERT - 문장에서 단어의 의미를 이해하고 순서를 수치화 : 인코더 특화모델

할루시네이션 - 환각 현상 : 없는말, 거짓말, 잘못된 정보들을 그럴듯하게 하는 현상
LLM이 언어를 생성할때, 뒤에 올 단어를 확률적으로 추론함


Ollama cmd 명령어

ollama list -> ollama 다운받은 리스트 확인
ollama rm 모델 -> 모델 제거

- Formatting은 프롬프트를 생성하는 형식을 지정하는 기술

코드를 출력해주는 프롬프트
1. 주석과 설명까지 포함해주는 모델
- 너는 파이썬 코드를 짜는데 도와주는 개발자 어시스턴트야! 코드를 줄때 주석을 달아주고 코드에 대한 설명을 해줘.
2. 간결하게 코드만 보여주는 모델
- 너는 파이썬 코드를 짜주는 개발자 도우미야! 답변은 코드만 줘.

너는 법 전문가야! 질문한 상황에 대한 죄목과 근거만 얘기해줘. 근거는 이유 추가하지말고 무슨 법위반인지만 얘기해줘. 답변은 죄목 : A 근거 : B 형태로 출력해줘.

자동차를 운전하다가 보행자 신호등이 붉은 색이었으나 돌발적으로 튀어나온 사람과 충돌하여, 사람이 전치 4주의 입원치료를 하였다.

프롬프트 엔지니어링 기법
!!!!! CoT(Chain of Thought) -
zero shot CoT : 프롬프트 마지막에 차근차근 생각해보자(Let's think step by step)를 넣는다

정규표현식 - 문자열의 패턴을 표현하는데 사용되는 형식

LLM이 참조하는 맥락의 정보가 잘 제공되지 않는다면 이상한 답변을 만들 수 밖에 없음


LangChain
LLM이 외부의 지식이나 계산능력을 가져와서


RAG 이론
문서를 가공 -> 임베더에 넣고 벡터화해서 Vector Index(FAISS)

사용자가 자연어 입력 -> 벡터 서치에서 검색한 결과물을 프롬프트생성을 query와 검색 결과물을 묶어서 LLM에 넣어 answer를 얻는다.

도큐먼트 청킹


프로젝트 주제선정 -> 도메인 지식이 있는 대상을 선정
- 도메인 지식이 없다면, 짧은 시간안에 빠른 학습으로 전문가 수준의 지식을 갖춰야 하나, 시간이 부족할 것임
- 문제 정의를 실현 가능한것, 난이도가 낮은것부터 시작할 것
- 투입할 정보와 산출할 정보 정의가 중요


발표 목표를 구체적으로 얘기한다


발표 피드백
기술적인 설명이 부족했다
- 쿼리를 보냈을때 데이터 파이프라인에 대한 설명
- 100을 발표하고 5만 발표한 느낌(기술적인 설명 부족으로)
한계와 개선사항의 매칭
- 한계는 이러한 문제점들이 있었고 이부분을 개선사항으로 향후 해결하겠다라는 발표의 흐름이 있는데 이러한 부분이 부족했다
- 한계에서 말하는 부분과 개선사항에서 말하는 부분이 매칭이 안된다.

시연영상에서 사람들이 쓰는 이상한 검색어를 넣어서 LLM의 장점을 살려라
쿼리를 할때 일반제품명을 할때와 옵션을 줬을때는 CSV파일이 나오지 않는다.

